import copy

import requests
from bs4 import BeautifulSoup
import re
import csv

import time
import random


def get_house_in_vienna():
    session = requests.Session()
    basic_url = 'https://www.zillow.com/'
    #url = 'https://www.zillow.com/homes/for_sale/Vienna,-VA_rb/'
    url = 'https://www.zillow.com/vienna-va/1_p'
    # headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0"}
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept-Language': 'en-US,en;q=0.5',
    }
    response = session.get(url, headers=headers)
    print(response.status_code)
    #print(response.text)
    soup = BeautifulSoup(response.text, 'html.parser')

    scripts = soup.find_all('script', attrs={"type":"application/ld+json"})
    lines = scripts[0].get_text(",")
    print(lines.split(','))
    fields = ['name', ]
    for script in scripts:
        lines = scripts[0].get_text(",")
        items = lines.split(',')


if __name__ == "__main__":
    print(get_house_in_vienna())
